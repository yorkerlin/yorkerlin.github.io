# About Me

PhD student working on computational aspects of differential, geometric, and algebraic structures (i.e., probability distributions and matrices). My research so far has mostly focused on geometric methods for **approximate inference** and  **numerical optimization** in machine learning.

For generalized natural-gradient (NG) methods, please see 
* Structured NG descent (ICML 2021): [Long Talk](https://download.dsf.tuhh.de/ig4ds22/videos/IG4DS-WuLin.mp4), [Short Talk](https://www.youtube.com/watch?v=vEY1ZxDJX8o&t=11s), [Paper](https://arxiv.org/abs/2102.07405), [Blog]({{ site.baseurl }}{% post_url 2021-07-05-GeomProj01 %})
* Riemannian gradient descent (ICML 2020): [Talk](https://www.youtube.com/watch?v=nu1hT-LExFg), [Paper](https://arxiv.org/abs/2002.10060)

* NG descent for exponential-family mixtures (ICML 2019): [Paper](https://arxiv.org/abs/1906.02914)
* NG descent for Bayesian deep learninng (ICML 2018): [Paper](https://arxiv.org/abs/1806.04854)
* NG variational inference for non-conjugate models (AI&Stats 2017): [Paper](https://arxiv.org/abs/1703.04265)


For an introduction to natural-gradient methods, see my [Blog]({{ site.baseurl }}{% post_url 2021-09-06-Geomopt01 %}).

For more publications, see my [Google Scholar](https://scholar.google.com/citations?user=sGl6muoAAAAJ&hl=en) page.

I review papers from conferences ([ICML](https://icml.cc/), [NeurIPS](https://nips.cc/), [ICLR](https://iclr.cc/), [AI&Stats](https://aistats.org/)), journals ([JMLR](https://www.jmlr.org/), [Information Geometry (Springer)](https://www.springer.com/journal/41884)), and workshops ([Optimization for Machine Learning](https://opt-ml.org/), [Advances in Approximate Bayesian Inference](http://approximateinference.org/)).

## Research Interests

I am interested in exploiting (hidden) structures and symmetries in machine learning with a focus on practical and numerical methods for optimization and statistical inference.

## News

{% include news.html %}
[Click here for all news](/news/)



