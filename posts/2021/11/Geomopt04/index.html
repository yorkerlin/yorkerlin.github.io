<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.12.0 by Michael Rose
  Copyright 2013-2018 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE.txt
-->
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Part IV: Natural and Riemannian  Gradient Descent - Wu Lin</title>
<meta name="description" content="Working in Progress (incomplete)">



<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="Wu Lin">
<meta property="og:title" content="Part IV: Natural and Riemannian  Gradient Descent">
<meta property="og:url" content="/posts/2021/11/Geomopt04/">


  <meta property="og:description" content="Working in Progress (incomplete)">







  <meta property="article:published_time" content="2021-11-15T00:00:00+00:00">





  

  


<link rel="canonical" href="/posts/2021/11/Geomopt04/">







  <script type="application/ld+json">
    {
      "@context": "http://schema.org",
      "@type": "Person",
      "name": "Wu Lin",
      "url": "https://github.com/pages/yorkerlin/yorkerlin.github.io",
      "sameAs": null
    }
  </script>







<!-- end _includes/seo.html -->


<link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Wu Lin Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">

<!--[if lte IE 9]>
  <style>
    /* old IE unsupported flexbox fixes */
    .greedy-nav .site-title {
      padding-right: 3em;
    }
    .greedy-nav button {
      position: absolute;
      top: 0;
      right: 0;
      height: 100%;
    }
  </style>
<![endif]-->


    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<script type="text/x-mathjax-config"> MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: "all" } } }); </script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/latest.js?config=TeX-MML-AM_CHTML' async></script>


<!-- end custom head snippets -->

  </head>

  <body class="layout--single mywide">

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    <div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        <a class="site-title" href="/">Wu Lin</a>
        <ul class="visible-links">
          
            
            <li class="masthead__menu-item">
              <a href="/" >Home</a>
            </li>
          
            
            <li class="masthead__menu-item">
              <a href="/news/" >News</a>
            </li>
          
            
            <li class="masthead__menu-item">
              <a href="/year-archive/" >Blog Posts</a>
            </li>
          
        </ul>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>

    <div class="initial-content">
      



<div id="main" role="main">
  

  <article class="page" itemscope itemtype="http://schema.org/CreativeWork">
    <meta itemprop="headline" content="Part IV: Natural and Riemannian  Gradient Descent">
    <meta itemprop="description" content="Working in Progress (incomplete)">
    <meta itemprop="datePublished" content="November 15, 2021">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title" itemprop="headline">Part IV: Natural and Riemannian  Gradient Descent
</h1>
          
            <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  5 minute read
</p>
          
        </header>
      

      <section class="page__content" itemprop="text">
        
        <p>Working in Progress (incomplete)</p>

<h2 id="goal">Goal</h2>
<p>This blog post should help readers to understand natural-gradient descent and Riemannian gradient descent.</p>

<p>We will give an informal introduction with a focus on high level of ideas.</p>

<h1 id="two-kinds-of-spaces">Two kinds of Spaces</h1>
<hr />
<p>As we disucssed in <a href="/posts/2021/10/Geomopt02/#riemannian-gradients-as-tangent-vectors-optional">Part II</a>, the parameter space $\Omega_\tau$ and the tangent space denoted by <code class="language-plaintext highlighter-rouge">$T\mathcal{M}_{\tau_0}$</code> at point $\tau_0$ are different spaces. Recall that the tangent space is a vector space and <code class="language-plaintext highlighter-rouge">$T\mathcal{M}_{\tau_0}=\mathcal{R}^K$</code> while the parameter space $\Omega_\tau$ is like a local vector space in <code class="language-plaintext highlighter-rouge">$\mathcal{R}^K$</code>, where $K$ is the dimension of the manifold. Moreover, $\Omega_\tau \subset T\mathcal{M}_{\tau_0}$ since  $\tau$ is an <a href="/posts/2021/09/Geomopt01/#intrinsic-parameterizations">intrinsic parametrization</a>.</p>

<p>The following figure illustrates the difference between the two spaces.</p>

<p><img src="/img/sphere.png" width="500" /></p>

<p>test citation <a class="citation" href="#demo">[1]</a></p>

<h1 id="natural-gradient-descent-in-an-intrinsic-parameter-space">Natural-gradient Descent in an Intrinsic Parameter Space</h1>
<hr />
<p>Using intrinstic parametrization $\tau$, an intuitive update like the Euclidean case is natural-gradient descent.
<code class="language-plaintext highlighter-rouge">$$
\begin{aligned}
\tau_{k+1} \leftarrow \tau_{k} - \alpha \hat{\mathbf{g}}_{\tau_k} 
\end{aligned}\tag{1}\label{1}
$$</code> where <code class="language-plaintext highlighter-rouge">$\hat{\mathbf{g}}_{\tau_k}$</code> is a natural/Riemannian gradient evaluated at point <code class="language-plaintext highlighter-rouge">$\tau_{k}$</code> and $\alpha&gt;0$ is a step-size.</p>

<p>The update in Eq. <code class="language-plaintext highlighter-rouge">$\eqref{1}$</code> is valid since the parameter space $\Omega_\tau$  has a local vector-space structure due to the intrinsic parametrization.
However, when $\Omega_\tau$ is a proper subset of $T\mathcal{M}_{\tau_k}$ (i.e., <code class="language-plaintext highlighter-rouge">$\Omega_\tau \neq T\mathcal{M}_{\tau_k} $</code>), the update in Eq. <code class="language-plaintext highlighter-rouge">$\eqref{1}$</code> is valid only when the step-size $\alpha$ is small enough so that  <code class="language-plaintext highlighter-rouge">$\tau_{k+1} \in \Omega_\tau$</code>.</p>

<blockquote>
  <p>Example:</p>

  <p>Consider a 1-dimensional  Gaussian family.
We specify an intrinsic parameterization $\mathbf{\tau}$  as <code class="language-plaintext highlighter-rouge">$ \{ \mathcal{N}(w |\mu,\sigma) \Big| \mu \in \mathcal{R}, \sigma&gt;0 \}$</code> with <code class="language-plaintext highlighter-rouge">$\tau = (\mu,\sigma) $</code>. <br /></p>

  <p>We have to properly select the step-size $\alpha$ for natural-gradient descent in  <code class="language-plaintext highlighter-rouge">$\eqref{1}$</code> due to the positivity constraint in $\sigma$.</p>

  <p>In multivariate Gaussian cases, we may have to handle a positive-definite constraint.</p>
</blockquote>

<h1 id="natural-gradient-descent-is-linearly-invariant">Natural-gradient Descent is Linearly Invariant</h1>
<p>Recall that in <a href="/posts/2021/11/Geomopt03/#Pparameter-transform-and-invariance">Part III</a>, we show that natural-gradients are invaraint under an intrinsic parameter transform.
The parameter transform can be non-linear.</p>

<p>It is natural to expect that natural-gradient descent has a similar property. However, natural-gradient descent is only invariant under  an intrinsic <strong>linear</strong> transform. Note that Newton’s method is also linearly invariant while Euclidean gradient descent is not.</p>

<p>Let’s consider the following (scalar) optimization problem on a manifold $\mathcal{M}$ with the Fisher-Rao metric $F$.
<code class="language-plaintext highlighter-rouge">$$
\begin{aligned}
\min_{x \in \mathcal{M}} h(x)
\end{aligned}\tag{2}\label{2}
$$</code></p>

<p>Note that $\mathcal{M}$ in general does not have a vector-space structure. 
We consider an intrinstic parameterization $\tau$ so that the parameter space $\Omega_\tau$ at least has a local  vector-space structure.
The problem in <code class="language-plaintext highlighter-rouge">$\eqref{2}$</code> can be re-expressed as below.
<code class="language-plaintext highlighter-rouge">$$
\begin{aligned}
\min_{\tau \in \Omega_\tau} h_\tau(\tau)
\end{aligned}
$$</code> where $h_\tau$ is the parameter representation of scalar smooth function $h$.</p>

<p>Natural gradient descent in this parameter space $\Omega_\tau$ is
<code class="language-plaintext highlighter-rouge">$$
\begin{aligned}
\tau_{k+1} \leftarrow \tau_{k} - \alpha \hat{\mathbf{g}}_{\tau_k} 
\end{aligned}\tag{3}\label{3}
$$</code> where <code class="language-plaintext highlighter-rouge">$\hat{\mathbf{g}}_{\tau_k} := [\mathbf{F}_\tau(\tau_k) ]^{-1} \nabla_\tau h_\tau(\tau_k)$</code> and the step-size $\alpha$ is small enough so that  $\tau_{k+1} \in \Omega_\tau$.</p>

<p>Consider another intrinstic parameterization $\lambda$ so that $\lambda=\mathbf{U} \tau$, where $\mathbf{U}$ is a constant (square) invertible matrix. 
When $\lambda$ is a valid parameterization, we know that <code class="language-plaintext highlighter-rouge">$\{ \mathbf{U}\tau |\tau \in\Omega_\tau \} 	\cap \Omega_\lambda \neq \emptyset$</code>.
For simplicity,  we further assume <code class="language-plaintext highlighter-rouge">$\{ \mathbf{U}\tau |\tau \in\Omega_\tau \} = \Omega_\lambda$</code>, where $\Omega_\lambda$ is the parameter space of $\lambda$. In general, we could use a smaller parameter space either $\Omega_\lambda$ or $\Omega_\tau$ so that this additional assumption holds.</p>

<p>Natural gradient descent in this parameter space $\Omega_\lambda$ is
<code class="language-plaintext highlighter-rouge">$$
\begin{aligned}
\lambda_{k+1} \leftarrow \lambda_{k} -  \alpha  \hat{\mathbf{g}}_{\lambda_k} 
\end{aligned}\tag{4}\label{4}
$$</code> where <code class="language-plaintext highlighter-rouge">$\hat{\mathbf{g}}_{\lambda_k} := [\mathbf{F}_\lambda(\lambda_k) ]^{-1} \nabla_\lambda h_\lambda(\lambda_k)$</code></p>

<p>Recall that we have the <a href="/posts/2021/11/Geomopt03/#parameter-transform-and-invariance">transform rule</a> for natural gradients as
<code class="language-plaintext highlighter-rouge">$$
\begin{aligned}
\hat{\mathbf{g}}_\tau= \mathbf{Q}  \hat{\mathbf{g}}_\lambda 
\end{aligned}
$$</code> where $Q_{ji}=\frac{\partial \tau^j(\lambda)}{\partial \lambda^i}$.</p>

<p>We can verify that $\mathbf{Q} = \mathbf{U}^{-1}$. Notice that $\tau_0 = \mathbf{U}^{-1} \lambda_0$ by construction.
The update in  <code class="language-plaintext highlighter-rouge">$\eqref{3}$</code> at iteration $k=1$ then can be re-expressed as
<code class="language-plaintext highlighter-rouge">$$
\begin{aligned}
\tau_{1} \leftarrow \tau_{0} -  \alpha  \hat{\mathbf{g}}_{\tau_0} = \mathbf{U}^{-1} \lambda_0 -  \alpha  \mathbf{U}^{-1}  \hat{\mathbf{g}}_{\lambda_0} 
\end{aligned}
$$</code></p>

<p>Therefore, it is easy to show that $\tau_k = \mathbf{U}^{-1} \lambda_k$ by induction. Updates in <code class="language-plaintext highlighter-rouge">$\eqref{3}$</code> and <code class="language-plaintext highlighter-rouge">$\eqref{4}$</code> are equivalent when $t$ is small enough.</p>

<h1 id="euclidean-gradient-descent-is-not-linearly-invariant">Euclidean Gradient Descent is NOT (Linearly) Invariant</h1>
<p>to do:
add an exapmle</p>

<h1 id="riemannian-gradient-descent-and-its-non-linear-invariance">Riemannian Gradient Descent and its (Non-linear) Invariance</h1>

<p>Now we discuss a gradient-based method that is invariant to any intrinsic parameter transform.
We will first introduce the concept of a (one-dimensional) geodesic $\gamma(t)$, which is the “shortest curve” on a manifold.
To specify a geodesic, we need to provide a starting point $x_0$ on the manifold and a tangent vector $\mathbf{v}_{x_0}$ evluated at point $x_0$.
The geodeisc is a solution of a system of second-order non-linear ordinary differential equations (ODE) with the following initial conditions.
<code class="language-plaintext highlighter-rouge">$$
\begin{aligned}
\gamma(0) = x_0; \,\,\,\,\,\,
\frac{d \gamma(t) }{d t} \Big|_{t=0} = \mathbf{v}_{x_0}
\end{aligned}
$$</code> where the geodesic is determined by the initial conditions.</p>

<p>Consider an intrinsic parametrization $\tau$, we can re-expressed  the  initial conditions as
<code class="language-plaintext highlighter-rouge">$$
\begin{aligned}
\gamma_\tau(0) = \tau_0; \,\,\,\,\,\,
\frac{d \gamma_\tau(t) }{d t} \Big|_{t=0} = \mathbf{v}_{\tau_0}
\end{aligned}
$$</code></p>

<p>We can define a manifold expoential map for a (geodesically complete) manifold  via the geodesic as 
<code class="language-plaintext highlighter-rouge">$$
\begin{aligned}
\mathrm{Exp}_{\tau_0}\colon  T\mathcal{M}_{\tau_0} &amp; \mapsto \mathcal{M}\\
\mathbf{v}_{\tau_0} &amp; \mapsto \gamma_\tau(1) \,\,\,\, \textrm{s.t.} \,\,\,\,\,\, \gamma_\tau(0) = \tau_0;\,\,\,\,\,\,
\frac{d \gamma_\tau(t) }{d t} \Big|_{t=0} = \mathbf{v}_{\tau_0}
\end{aligned}
$$</code> where the completeness is required if the domain of the expoential map is the whole tangent space.</p>

<p>We will use the expoential map to define Riemannian gradient descent without specifying complicated  differential equations (e.g., Christoffel symbols) in the geodesic.</p>

<p>Under intrinsic parametrization $\tau$, (exact) Riemannian gradient descent is defined as 
<code class="language-plaintext highlighter-rouge">$$
\begin{aligned}
\tau_{k+1} \leftarrow \mathrm{Exp}_{\tau_k} (- \alpha  \hat{\mathbf{g}}_{\tau_k} ) 
\end{aligned}
$$</code></p>

<p>The invariance of this update is due to the uniqueness of ODE and transform rules for natural-gradients, Fisher information matrix, and Christoffel symbols. We will not discuss this further in this post to avoid complicated derivations. 
Although Riemannian gradient descent is nice, the expoential map or the geodesic often does not have a closed form expression.</p>

<h1 id="natural-gradient-descent-as-an-approximated-method">Natural-gradient Descent as an Approximated Method</h1>

<p>Natural-gradient descent can be viewed as a first-order (linear) approximation of the geodesic, which implies that natural-gradient descent is indeed an inexact Riemannian gradient update.
Natural-gradient descent only is linearly invariant due to the approximation.</p>

<p>Consider a first-order Taylor approximation at $t=0$ of the geodesic shown below.
<code class="language-plaintext highlighter-rouge">$$
\begin{aligned}
\gamma_\tau(t) \approx \gamma_\tau(0) + \frac{d  \gamma_\tau(t)}{d t} \Big|_{t=0} (t-0)  
\end{aligned}
$$</code></p>

<p>Recall that the  expoential map  is defined via the geodesic  <code class="language-plaintext highlighter-rouge">$\gamma_\tau(1)$</code>.
We can similarly define an approximated  expoential map (A.K.A. the Euclidean retraction map)  as
<code class="language-plaintext highlighter-rouge">$$
\begin{aligned}
\mathrm{Ret}_{\tau_0}(\mathbf{v}_{\tau_0}) := \gamma_\tau(0) + \frac{d  \gamma_\tau(t)}{d t} \Big|_{t=0} (1-0) =\tau_0 + \mathbf{v}_{\tau_0}
\end{aligned}
$$</code></p>

<p>Therefore, the inexact Riemannian gradient update is defined as 
<code class="language-plaintext highlighter-rouge">$$
\begin{aligned}
\tau_{k+1} \leftarrow \mathrm{Ret}_{\tau_k} (- \alpha  \hat{\mathbf{g}}_{\tau_k} )  = \tau_k  - \alpha  \hat{\mathbf{g}}_{\tau_k}
\end{aligned}
$$</code> which is eactly natural-gradient descent.</p>

<hr />
<p>to do: all kinds of approx to get NGD (point distance != vector distance)
We can also show that NGD can be dervied from 
<code class="language-plaintext highlighter-rouge">$$
\begin{aligned}
\tau_{k+1} = \arg\max_{y \in \mathcal{R}^K } \{ \langle \mathbf{g}_{\tau_k}, y\rangle   + \mathrm{D}(y,\tau_k) \}
\end{aligned}
$$</code> where <code class="language-plaintext highlighter-rouge">$\mathbf{g}_{\tau_k}$</code> is a Eulcidean gradient and $\mathrm{D}(y,\tau_k)$ is a secord-order Taylor approximation of the KL divergence <code class="language-plaintext highlighter-rouge">$\mathrm{KL} [q(w|\tau_k) || q(w|y)]$</code>  at $\tau_k$</p>

<p>to do: mention  mirror descent and <code class="language-plaintext highlighter-rouge">$\mathrm{D}(y,\tau_k)$</code> becomes exact for expoential family (will be discussed more in Part V)</p>

<h1 id="references">References</h1>
<p class="bibliography"><p><span id="demo">[1] mytest, "test demo v2," <i>demo</i> (2019).</span></p></p>

        
      </section>

      <footer class="page__meta">
        
        
  


  
  
  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-tags" aria-hidden="true"></i> Tags: </strong>
    <span itemprop="keywords">
    
      
      
      <a href="/tags/#information-geometry" class="page__taxonomy-item" rel="tag">Information Geometry</a><span class="sep">, </span>
    
      
      
      <a href="/tags/#natural-gradient-descent" class="page__taxonomy-item" rel="tag">Natural Gradient Descent</a><span class="sep">, </span>
    
      
      
      <a href="/tags/#riemannian-manifold" class="page__taxonomy-item" rel="tag">Riemannian Manifold</a>
    
    </span>
  </p>




        
          <p class="page__date"><strong><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> Updated:</strong> <time datetime="2021-11-15T00:00:00+00:00">November 15, 2021</time></p>
        
      </footer>

      <section class="page__share">
  
    <h4 class="page__share-title" data-translate="share_on_label">Share on</h4>
  

  <a href="https://twitter.com/intent/tweet?text=Part+IV%3A+Natural+and+Riemannian++Gradient+Descent%20%2Fposts%2F2021%2F11%2FGeomopt04%2F" class="btn btn--twitter" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Twitter"><i class="fab fa-fw fa-twitter" aria-hidden="true"></i><span> Twitter</span></a>

  <a href="https://www.facebook.com/sharer/sharer.php?u=%2Fposts%2F2021%2F11%2FGeomopt04%2F" class="btn btn--facebook" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Facebook"><i class="fab fa-fw fa-facebook" aria-hidden="true"></i><span> Facebook</span></a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=%2Fposts%2F2021%2F11%2FGeomopt04%2F" class="btn btn--linkedin" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on LinkedIn"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>



     

  <script src="https://utteranc.es/client.js"
    repo=yorkerlin/yorkerlin.github.io
    issue-term=url
    label=blog-comments
    theme=github-light
    crossorigin= "anonymous"
    async>
  </script>




</section>


      
  <nav class="pagination">
    
      <a href="/posts/2021/11/Geomopt03/" class="pagination--pager" title="Part III: Invariance of Natural-Gradients
">Previous</a>
    
    
      <a href="#" class="pagination--pager disabled">Next</a>
    
  </nav>

    </div>

    
  </article>

  
  
    <div class="page__related">
      <h4 class="page__related-title">You may also enjoy</h4>
      <div class="grid__wrapper">
        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/posts/2021/11/Geomopt03/" rel="permalink">Part III: Invariance of Natural-Gradients
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  7 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">Goal
This blog post should help readers to understand the invariance of natural-gradients.
We will also discuss why standard Euclidean gradients are NOT inva...</p>
  </article>
</div>
        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/posts/2021/10/Geomopt02/" rel="permalink">Part II: the Space of Natural-Gradients at one Point
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  10 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">Goal
This blog post should help readers to understand natural-gradients, which are known as Riemannian gradients with the Fisher-Rao metric.
The space of nat...</p>
  </article>
</div>
        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/posts/2021/09/Geomopt01/" rel="permalink">Part I: Manifolds with the Fisher-Rao Metric
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  12 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">Goal
This blog post should help readers to understand the Fisher-Rao metric also known as the Fisher information matrix (FIM).

  FIM plays an essential role...</p>
  </article>
</div>
        
      </div>
    </div>
  
  
</div>
    </div>

    

    <div class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>Follow</strong></li>
    
    
    
    
      <li><a href="https://github.com/yorkerlin"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
    
    
    
    <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2021 Wu Lin. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>
  <script src="https://use.fontawesome.com/releases/v5.2.0/js/all.js"></script>






-->
    <!--

  <script src="https://utteranc.es/client.js"
    repo=yorkerlin/yorkerlin.github.io
    issue-term=url
    label=blog-comments
    theme=github-light
    crossorigin= "anonymous"
    async>
  </script>

-->
  





  
    <script src="/assets/js/custom.js"></script>
  
    <script src="/assets/js/translations.js"></script>
  
    <script src="/assets/js/math-code.js"></script>
  



  </body>
</html>

